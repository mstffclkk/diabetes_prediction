{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T11:45:12.302978385Z",
     "start_time": "2023-12-19T11:45:11.912362982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import  VotingClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb51c0a2c95a4d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T11:45:12.311487014Z",
     "start_time": "2023-12-19T11:45:12.259858759Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "     It gives the names of categorical, numerical and categorical but cardinal variables in the data set.\n",
    "     Note: Categorical variables with numerical appearance are also included.\n",
    "\n",
    "     parameters\n",
    "     ------\n",
    "         dataframe: dataframe\n",
    "                 Dataframe from which variable names are to be taken\n",
    "         cat_th: int, optional\n",
    "                 Class threshold value for variables that are numeric but categorical\n",
    "         car_th: int, optional\n",
    "                 class threshold for categorical but cardinal variables\n",
    "\n",
    "     returns\n",
    "     ------\n",
    "         cat_cols: list\n",
    "                 Categorical variable list\n",
    "         num_cols: list\n",
    "                 Numerical variable list\n",
    "         cat_but_car: list\n",
    "                 List of cardinal variables with categorical view\n",
    "\n",
    "     examples\n",
    "     ------\n",
    "         import seaborn as sns\n",
    "         df = sns.load_dataset(\"iris\")\n",
    "         print(grab_col_names(df))\n",
    "\n",
    "\n",
    "     Notes\n",
    "     ------\n",
    "         cat_cols + num_cols + cat_but_car = total number of variables\n",
    "         num_but_cat is inside cat_cols.\n",
    "\n",
    "    \"\"\"\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"category\", \"object\", \"bool\"]]\n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if\n",
    "                   dataframe[col].nunique() < 10 and dataframe[col].dtypes in [\"int64\", \"float64\", \"int32\", \"float32\"]]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if\n",
    "                   dataframe[col].nunique() > 20 and str(dataframe[col].dtypes) in [\"category\", \"object\"]]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in [\"int64\", \"float64\", \"int32\", \"float32\"]]\n",
    "    num_cols = [col for col in num_cols if col not in cat_cols]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\\nVariables: {dataframe.shape[1]}\\ncat_cols: {len(cat_cols)}\\n\"\n",
    "          f\"num_cols: {len(num_cols)}\\ncat_but_car: {len(cat_but_car)}\\nnum_but_cat: {len(num_but_cat)}\")\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable, q1=0.05, q3=0.95):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1=0.05, q3=0.95)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "    \n",
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe\n",
    "\n",
    "def diabetes_data_prep(dataframe):\n",
    "    dataframe.columns = [col.upper() for col in dataframe.columns]\n",
    "\n",
    "    # Creation of new variables.\n",
    "    \n",
    "    # Age : Categorizing the age variable and creating a new age variable.\n",
    "    dataframe.loc[(dataframe['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n",
    "    \n",
    "    # Glucose : Convert glucose value to a categorical variable\n",
    "    dataframe['NEW_GLUCOSE_CAT'] = pd.cut(x=dataframe['GLUCOSE'], bins=[-1, 139, 200, 300], labels=[\"normal\", \"prediabetes\", \"diabetes\"])\n",
    "    \n",
    "    # BMI below 18.5 is underweight, between 18.5 and 24.9 is healthy, between 24.9 and 29.9 is overweight and above 30 is obese\n",
    "    dataframe['NEW_BMI_RANGE'] = pd.cut(x=dataframe['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
    "                                 labels=[\"underweight\", \"healthy\", \"overweight\", \"obese\"])\n",
    "    \n",
    "    # BloodPressure\n",
    "    dataframe['NEW_BLOODPRESSURE'] = pd.cut(x=dataframe['BLOODPRESSURE'], bins=[-1, 79, 89, 123], labels=[\"normal\", \"hs1\", \"hs2\"])\n",
    "\n",
    "    # # Yaş ve beden kitle indeksini bir arada düşünerek kategorik değişken oluşturma\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['BMI'] < 18.5), \"NEW_AGE_BMI_CAT\"] = 'young_underweight'\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['BMI'] >= 18.5) & (dataframe['BMI'] < 24.9), \"NEW_AGE_BMI_CAT\"] = 'young_healthy'\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['BMI'] >= 24.9) & (dataframe['BMI'] < 29.9), \"NEW_AGE_BMI_CAT\"] = 'young_overweight'\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['BMI'] >= 29.9), \"NEW_AGE_BMI_CAT\"] = 'young_obese'\n",
    "    \n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['BMI'] < 18.5), \"NEW_AGE_BMI_CAT\"] = 'middleage_underweight'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['BMI'] >= 18.5) & (dataframe['BMI'] < 24.9), \"NEW_AGE_BMI_CAT\"] = 'middleage_healthy'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['BMI'] >= 24.9) & (dataframe['BMI'] < 29.9), \"NEW_AGE_BMI_CAT\"] = 'middleage_overweight'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['BMI'] >= 29.9), \"NEW_AGE_BMI_CAT\"] = 'middleage_obese'\n",
    "    \n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['BMI'] < 18.5), \"NEW_AGE_BMI_CAT\"] = 'old_underweight'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['BMI'] >= 18.5) & (dataframe['BMI'] < 24.9), \"NEW_AGE_BMI_CAT\"] = 'old_healthy'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['BMI'] >= 24.9) & (dataframe['BMI'] < 29.9), \"NEW_AGE_BMI_CAT\"] = 'old_overweight'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['BMI'] >= 29.9), \"NEW_AGE_BMI_CAT\"] = 'old_obese'\n",
    "    \n",
    "    # Yaş ve Glikoz değerlerini bir arada düşünerek kategorik değişken oluşturma\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['GLUCOSE'] < 139), \"NEW_AGE_GLUCOSE_CAT\"] = 'young_normal'\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['GLUCOSE'] >= 139) & (dataframe['GLUCOSE'] < 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'young_prediabetes'\n",
    "    dataframe.loc[(dataframe['AGE'] < 35) & (dataframe['GLUCOSE'] >= 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'young_diabetes'\n",
    "    \n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['GLUCOSE'] < 139), \"NEW_AGE_GLUCOSE_CAT\"] = 'middleage_normal'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['GLUCOSE'] >= 139) & (dataframe['GLUCOSE'] < 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'middleage_prediabetes'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55) & (dataframe['GLUCOSE'] >= 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'middleage_diabetes'\n",
    "    \n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['GLUCOSE'] < 139), \"NEW_AGE_GLUCOSE_CAT\"] = 'old_normal'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['GLUCOSE'] >= 139) & (dataframe['GLUCOSE'] < 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'old_prediabetes'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55) & (dataframe['GLUCOSE'] >= 200), \"NEW_AGE_GLUCOSE_CAT\"] = 'old_diabetes'\n",
    "    \n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe, cat_th=5, car_th=20)\n",
    "    \n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    df = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
    "\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    replace_with_thresholds(df, \"INSULIN\")\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(df[num_cols])\n",
    "    df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)\n",
    "\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X = df.drop([\"OUTCOME\"], axis=1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def base_models(X, y, scoring=\"roc_auc\"):\n",
    "    print(\"Base Models....\")\n",
    "    classifiers = [('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "                   ('LightGBM', LGBMClassifier(verbose=-1)),\n",
    "                   ('CatBoost', CatBoostClassifier(verbose=False))\n",
    "                   ]\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
    "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")\n",
    "\n",
    "\n",
    "        \n",
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8],\n",
    "                  \"n_estimators\": [100, 200]}\n",
    "\n",
    "lightgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "                   \"n_estimators\": [300, 500]}\n",
    "\n",
    "catboost_params = {\"iterations\": [200, 500],\n",
    "                   \"learning_rate\": [0.01, 0.1]}\n",
    "\n",
    "classifiers = [('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgboost_params),\n",
    "               ('LightGBM', LGBMClassifier(verbose=-1), lightgbm_params),\n",
    "               ('CatBoost', CatBoostClassifier(verbose=False), catboost_params)]  \n",
    "\n",
    "def hyperparameter_optimization(X, y, cv=3, scoring=\"roc_auc\"):\n",
    "    print(\"Hyperparameter Optimization....\")\n",
    "    best_models = {}\n",
    "    for name, classifier, params in classifiers:\n",
    "        print(f\"########## {name} ##########\")\n",
    "        cv_results = cross_validate(classifier, X, y, cv=cv, scoring=scoring)\n",
    "        print(f\"{scoring} (Before): {round(cv_results['test_score'].mean(), 4)}\")\n",
    "\n",
    "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)\n",
    "        final_model = classifier.set_params(**gs_best.best_params_)\n",
    "\n",
    "        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)\n",
    "        print(f\"{scoring} (After): {round(cv_results['test_score'].mean(), 4)}\")\n",
    "        print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
    "        best_models[name] = final_model\n",
    "    return best_models\n",
    "\n",
    "def voting_classifier(best_models, X, y):\n",
    "    print(\"Voting Classifier...\")\n",
    "\n",
    "    voting_clf = VotingClassifier(estimators=[('XGBoost', best_models[\"XGBoost\"]),\n",
    "                                              ('LightGBM', best_models[\"LightGBM\"]),\n",
    "                                              ('CatBoost', best_models[\"CatBoost\"])],\n",
    "                                  voting='soft').fit(X, y)\n",
    "\n",
    "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
    "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
    "    print(f\"F1Score: {cv_results['test_f1'].mean()}\")\n",
    "    print(f\"ROC_AUC: {cv_results['test_roc_auc'].mean()}\")\n",
    "    return voting_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbd2943f6bc74ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:11:38.341931486Z",
     "start_time": "2023-12-19T12:10:45.916773490Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start...\n",
      "Observations: 768\n",
      "Variables: 15\n",
      "cat_cols: 7\n",
      "num_cols: 8\n",
      "cat_but_car: 0\n",
      "num_but_cat: 1\n",
      "Observations: 768\n",
      "Variables: 34\n",
      "cat_cols: 26\n",
      "num_cols: 8\n",
      "cat_but_car: 0\n",
      "num_but_cat: 1\n",
      "Base Models....\n",
      "roc_auc: 0.8042 (XGBoost) \n",
      "roc_auc: 0.8027 (LightGBM) \n",
      "roc_auc: 0.8364 (CatBoost) \n",
      "Hyperparameter Optimization....\n",
      "########## XGBoost ##########\n",
      "roc_auc (Before): 0.818\n",
      "roc_auc (After): 0.818\n",
      "XGBoost best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "########## LightGBM ##########\n",
      "roc_auc (Before): 0.8183\n",
      "roc_auc (After): 0.8183\n",
      "LightGBM best params: {'learning_rate': 0.01, 'n_estimators': 300}\n",
      "\n",
      "########## CatBoost ##########\n",
      "roc_auc (Before): 0.8381\n",
      "roc_auc (After): 0.8381\n",
      "CatBoost best params: {'iterations': 500, 'learning_rate': 0.01}\n",
      "\n",
      "Voting Classifier...\n",
      "Accuracy: 0.7721354166666666\n",
      "F1Score: 0.6546764846378396\n",
      "ROC_AUC: 0.8296285488076537\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"/home/mustafa/PycharmProjects/diabetes_pred/diabetes.csv\")\n",
    "    X, y = diabetes_data_prep(df)\n",
    "    base_models(X, y)\n",
    "    best_models = hyperparameter_optimization(X, y)\n",
    "    voting_clf = voting_classifier(best_models, X, y)\n",
    "    joblib.dump(voting_clf, \"voting_clf.pkl\")\n",
    "    \n",
    "    return voting_clf\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start...\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250968882841bd07",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
